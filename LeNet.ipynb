{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet (18/06/08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 导入mnist的数据集\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# read_data_sets(train_dir,fake_data=False,one_hot=True,dtype=dtypes.float32,\n",
    "                   #reshape=True, validation_size=5000,seed=None)\n",
    "# 过程就是下载数据，解压数据，返回datasets，包括train，validation,test三个部分\n",
    "# one_hot = True 是考虑多类情况。非onehot，标签是0 1 2 3 这样的\n",
    "# one_hot 就是一个长度为 n 的数组，只有一个元素是1，其他元素是0\n",
    "# mnist的标签就是这样的，所以one_hot = True\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "def weight(shape):  \n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)  \n",
    "    return tf.Variable(initial)  \n",
    "  \n",
    "def bias(shape):  \n",
    "    initial = tf.constant(0.1,shape = shape)  \n",
    "    return tf.Variable(initial)  \n",
    "  \n",
    "def conv2(x,W):  \n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='VALID')  \n",
    "  \n",
    "def max_pool(x):  \n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')  \n",
    "  \n",
    "x = tf.placeholder(tf.float32,[None,784])  \n",
    "y_ = tf.placeholder(tf.float32,[None,10])  \n",
    "x_image=tf.pad(tf.reshape(x,[-1,28,28,1]),[[0,0],[2,2],[2,2],[0,0]])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一层卷积 + 池化\n",
    "# 6个5x5的卷积核\n",
    "W_conv1 = weight([5,5,1,6])\n",
    "b_conv1 = bias([6])\n",
    "h_conv1 = tf.nn.relu(conv2(x_image,W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二层卷积 + 池化\n",
    "# 16个5x5的卷积核\n",
    "W_conv2 = weight([5,5,6,16])\n",
    "b_conv2 = bias([16])\n",
    "h_conv2 = tf.nn.relu(conv2(h_pool1,W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第三层卷积\n",
    "# 120个5x5的卷积核\n",
    "W_conv3 = weight([5,5,16,120])\n",
    "b_conv3 = bias([120])\n",
    "h_conv3 = tf.nn.relu(conv2(h_pool2,W_conv3) + b_conv3)\n",
    "h_conv3_re  = tf.reshape(h_conv3,[-1,120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keep_prob = tf.placeholder(tf.float32)  \n",
    "        \n",
    "                   \n",
    "# 全连接层\n",
    "W_fc1 = weight([1*1*120,84])\n",
    "b_fc1 = bias([84])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv3_re,W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "# 输出层\n",
    "W_o = weight([1*1*84,10])\n",
    "b_o = bias([10])\n",
    "y_predict = tf.nn.softmax(tf.matmul(h_fc1_drop,W_o) + b_o)\n",
    "\n",
    "\n",
    "                   \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.08\n",
      "step 1000, training accuracy 0.86\n",
      "step 2000, training accuracy 0.86\n",
      "step 3000, training accuracy 0.9\n",
      "step 4000, training accuracy 0.96\n",
      "step 5000, training accuracy 0.92\n",
      "step 6000, training accuracy 1\n",
      "step 7000, training accuracy 0.96\n",
      "step 8000, training accuracy 0.96\n",
      "step 9000, training accuracy 0.96\n",
      "step 10000, training accuracy 0.98\n",
      "step 11000, training accuracy 0.94\n",
      "step 12000, training accuracy 0.94\n",
      "step 13000, training accuracy 0.94\n",
      "step 14000, training accuracy 0.98\n",
      "step 15000, training accuracy 1\n",
      "step 16000, training accuracy 0.98\n",
      "step 17000, training accuracy 0.96\n",
      "step 18000, training accuracy 1\n",
      "step 19000, training accuracy 0.98\n",
      "step 19999, training accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cross_entropy = tf.reduce_mean(  \n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_predict)) \n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)  \n",
    "# train_step = tf.train.GradientDescentOptimizer(1e-4).minimize(cross_entropy)  \n",
    "\n",
    "# 算正确率\n",
    "correct_prediction = tf.equal(tf.argmax(y_predict, 1), tf.argmax(y_, 1))  \n",
    "\n",
    "# 运行上面这个函数，会生成一组向量，如：[True, False, True, True]。\n",
    "# 把它映射成浮点数，然后，计算它们的均值\n",
    "# cast(x, dtype, name=None) ,将x的数据格式转化成dtype\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))  \n",
    "\n",
    "#开始训练\n",
    "sess.run(tf.global_variables_initializer())  \n",
    "for i in range(20000):  \n",
    "    # 50一组 把mnist上的东西赋给了batch\n",
    "    # 之后x = batch[0],y_ = batch[1]\n",
    "    batch = mnist.train.next_batch(50) \n",
    "    \n",
    "    if i % 1000 == 0:  \n",
    "        train_accuracy = accuracy.eval(feed_dict={  \n",
    "            x: batch[0], y_: batch[1], keep_prob: 1.0})  \n",
    "        print(\"step %d, training accuracy %g\" % (i, train_accuracy))  \n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})  \n",
    "\n",
    "print(\"step %d, training accuracy %g\" % (i, train_accuracy))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
